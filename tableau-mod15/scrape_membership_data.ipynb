{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### webscraper to download membership data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize browser instance\n",
    "executable_path = {'executable_path':'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visit url\n",
    "url = 'https://www.citibikenyc.com/system-data/'\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn into soup\n",
    "html = browser.html\n",
    "soup = bs(html,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all unordered lists\n",
    "lists = soup.find_all('ul')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all bullets\n",
    "items = lists[4].find_all('li')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab all hyperlinks\n",
    "urls = []\n",
    "for item in items:\n",
    "    for link in item.find_all('a'):\n",
    "        urls.append(link['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm 22 hyperlinks found\n",
    "len(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# check for data sources\n",
    "exists = []\n",
    "for dest in urls:\n",
    "    browser.visit(dest)\n",
    "    exists.append(browser.is_text_present('Get the data', wait_time=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data sources found: 22\n",
      "Data sources not found: 0\n"
     ]
    }
   ],
   "source": [
    "# confirm 22 sources found\n",
    "print(f'Data sources found: {exists.count(True)}')\n",
    "print(f'Data sources not found: {exists.count(False)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### download each CSV file and rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate contextual labels\n",
    "labels = []\n",
    "for item in items:\n",
    "    year = item.text[:4]\n",
    "    for link in item.find_all('a'):\n",
    "        span = link.text.replace(' ','').replace(';','')\n",
    "        labels.append(year + '-' + span + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# change directory to downloads\n",
    "path = 'C:/Users/nssas/Downloads/'\n",
    "os.chdir(path)\n",
    "\n",
    "# visit each source and download on click\n",
    "dest = 'D:/tableau_csvs/membership_data/'\n",
    "for i, url in enumerate(urls):\n",
    "    browser.visit(url)\n",
    "    browser.click_link_by_partial_text('Get the data')\n",
    "    \n",
    "    time.sleep(1)\n",
    "\n",
    "    # rename file inplace, move to resources directory\n",
    "    for file in os.listdir('.'):\n",
    "        if file.startswith('data-'):\n",
    "            os.rename(file,dest+labels[i])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# navigate back to project directory\n",
    "nav = 'D:/tableau_csvs/'\n",
    "os.chdir(nav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013-Launch-Sep.csv\n",
      "2013-Oct-Dec.csv\n",
      "2014-Apr-Jun.csv\n",
      "2014-Jan-Mar.csv\n",
      "2014-Jul-Sep.csv\n",
      "2014-Oct-Dec.csv\n",
      "2015-Apr-Jun.csv\n",
      "2015-Jan-Mar.csv\n",
      "2015-Jul-Sep.csv\n",
      "2015-Oct-Dec.csv\n",
      "2016-Apr-Jun.csv\n",
      "2016-Jan-Mar.csv\n",
      "2016-Jul-Sep.csv\n",
      "2016-Oct-Dec.csv\n",
      "2017-Apr-Jun.csv\n",
      "2017-Jan-Mar.csv\n",
      "2017-Jul-Sep.csv\n",
      "2017-Oct-Dec.csv\n",
      "2018-Apr-Jun.csv\n",
      "2018-Jan-Mar.csv\n",
      "2018-Jul-Sep.csv\n",
      "2018-Oct-Dec.csv\n"
     ]
    }
   ],
   "source": [
    "# confirm files are renamed\n",
    "for file in os.listdir('membership_data'):\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close browser instance\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cut down data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# check difference in data columns\n",
    "for file in os.listdir('membership_data'):\n",
    "    df = pd.read_csv(f'membership_data/{file}')\n",
    "    print(len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique = []\n",
    "for file in os.listdir('membership_data/'):\n",
    "    df = pd.read_csv(f'membership_data/{file}')\n",
    "    cols = df.columns.values.tolist()\n",
    "    for col in cols:\n",
    "        if col not in unique:\n",
    "            unique.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Date',\n",
       " 'Trips over the past 24-hours (midnight to 11:59pm)',\n",
       " 'Cumulative trips (since launch):',\n",
       " 'Miles traveled today (midnight to 11:59 pm)',\n",
       " 'Miles traveled to date:',\n",
       " 'Total Annual Members',\n",
       " 'Annual Member Sign-Ups (midnight to 11:59 pm)',\n",
       " '24-Hour Passes Purchased (midnight to 11:59 pm)',\n",
       " '7-Day Passes Purchased (midnight to 11:59 pm)',\n",
       " '24-Hour Passes Purchased (midnight to 11:59 pm)\\t7-Day Passes Purchased (midnight to 11:59 pm)',\n",
       " 'Total Annual Memberships Sold',\n",
       " 'Cumulative trips (since launch)',\n",
       " 'Miles traveled to date',\n",
       " 'Total Annual Members (All Time)',\n",
       " '3-Day Passes Purchased (midnight to 11:59 pm)']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# there's no data for the last tabbed 7-day, so just using .startswith()len\n",
    "unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSVs with 3-day passes: 11\n",
      "CSVs with 7-day passes: 11\n",
      "CSVs with 24-hr passes: 22\n"
     ]
    }
   ],
   "source": [
    "a = []\n",
    "b = []\n",
    "c = []\n",
    "\n",
    "for file in os.listdir('membership_data'):\n",
    "    df = pd.read_csv(f'membership_data/{file}')\n",
    "    cols = df.columns.tolist()\n",
    "    for col in cols:\n",
    "        if col.startswith('3-Day Passes'):\n",
    "            a.append(col)\n",
    "        if col.startswith('7-Day Passes'):\n",
    "            b.append(col)\n",
    "        if col.startswith('24-Hour Passes'):\n",
    "            c.append(col)\n",
    "            \n",
    "print(f'CSVs with 3-day passes: {len(a)}')\n",
    "print(f'CSVs with 7-day passes: {len(b)}')\n",
    "print(f'CSVs with 24-hr passes: {len(c)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### notes for me\n",
    "\n",
    "constant:\n",
    "* Date\n",
    "* Trips over the past 24-hours (midnight to 11:59pm)\n",
    "* Miles traveled today\n",
    "* Total Annual Members/Memberships Sold\n",
    "* 24-Hour Passes Purchased\n",
    "* 11 7-Day, 11 3-Day\n",
    "\n",
    "to do:\n",
    "* combine '24-Hour Passes'; no data for the last tabbed 7-day, so just using .startswith()\n",
    "* combine 'Miles traveled to date'\n",
    "* no need for cumulative trips, just count totals\n",
    "* 7 day passes end in 2016, switch to 3 day passes\n",
    "* missing 7-day passes for 2013-oct-dec\n",
    "* both passes available for 2016-apr-jun\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = ['Date',\n",
    "        'Trips over the past 24-hours',\n",
    "        'Miles traveled today',\n",
    "        'Total Annual Members',\n",
    "        '24-Hour Passes',\n",
    "        '7-Day Passes',\n",
    "        '3-Day Passes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in 2013-Launch-Sep.csv: 6\n",
      "Columns in 2013-Oct-Dec.csv: 5\n",
      "Columns in 2014-Apr-Jun.csv: 6\n",
      "Columns in 2014-Jan-Mar.csv: 6\n",
      "Columns in 2014-Jul-Sep.csv: 6\n",
      "Columns in 2014-Oct-Dec.csv: 6\n",
      "Columns in 2015-Apr-Jun.csv: 6\n",
      "Columns in 2015-Jan-Mar.csv: 6\n",
      "Columns in 2015-Jul-Sep.csv: 6\n",
      "Columns in 2015-Oct-Dec.csv: 6\n",
      "Columns in 2016-Apr-Jun.csv: 7\n",
      "Columns in 2016-Jan-Mar.csv: 6\n",
      "Columns in 2016-Jul-Sep.csv: 6\n",
      "Columns in 2016-Oct-Dec.csv: 6\n",
      "Columns in 2017-Apr-Jun.csv: 6\n",
      "Columns in 2017-Jan-Mar.csv: 6\n",
      "Columns in 2017-Jul-Sep.csv: 6\n",
      "Columns in 2017-Oct-Dec.csv: 6\n",
      "Columns in 2018-Apr-Jun.csv: 6\n",
      "Columns in 2018-Jan-Mar.csv: 6\n",
      "Columns in 2018-Jul-Sep.csv: 6\n",
      "Columns in 2018-Oct-Dec.csv: 6\n"
     ]
    }
   ],
   "source": [
    "# all should be 6 except for 2013-oct-dec (no day passes)\n",
    "# and 2016-apr-jun (3 and 7-day)\n",
    "for file in os.listdir('membership_data/'):\n",
    "    df = pd.read_csv(f'membership_data/{file}')\n",
    "    holder = []\n",
    "    for col in df.columns:\n",
    "        for item in keep:\n",
    "            if col.startswith(item):\n",
    "                holder.append(col)\n",
    "\n",
    "    dic = {}\n",
    "    for i, col in enumerate(holder):\n",
    "        if col.startswith('3'):\n",
    "            dic[col] = keep[-1]\n",
    "        elif col.startswith('7'):\n",
    "            dic[col] = keep[-2]\n",
    "        else:\n",
    "            dic[col] = keep[i]\n",
    "\n",
    "    print(f'Columns in {file}: {len(dic)}')\n",
    "    df[holder].rename(index=str,columns=dic).to_csv(f'membership_data/{file}',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Date': 'Date',\n",
       " 'Trips over the past 24-hours (midnight to 11:59pm)': 'Trips over the past 24-hours',\n",
       " 'Miles traveled today (midnight to 11:59 pm)': 'Miles traveled today',\n",
       " 'Total Annual Members (All Time)': 'Total Annual Members',\n",
       " '24-Hour Passes Purchased (midnight to 11:59 pm)': '24-Hour Passes',\n",
       " '3-Day Passes Purchased (midnight to 11:59 pm)': '3-Day Passes'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013-Launch-Sep.csv\n",
      "2013-Oct-Dec.csv\n",
      "----\n",
      "2014-Apr-Jun.csv\n",
      "2014-Jan-Mar.csv\n",
      "2014-Jul-Sep.csv\n",
      "2014-Oct-Dec.csv\n",
      "----\n",
      "2015-Apr-Jun.csv\n",
      "2015-Jan-Mar.csv\n",
      "2015-Jul-Sep.csv\n",
      "2015-Oct-Dec.csv\n",
      "----\n",
      "2016-Apr-Jun.csv\n",
      "2016-Jan-Mar.csv\n",
      "2016-Jul-Sep.csv\n",
      "2016-Oct-Dec.csv\n",
      "----\n",
      "2017-Apr-Jun.csv\n",
      "2017-Jan-Mar.csv\n",
      "2017-Jul-Sep.csv\n",
      "2017-Oct-Dec.csv\n",
      "----\n",
      "2018-Apr-Jun.csv\n",
      "2018-Jan-Mar.csv\n",
      "2018-Jul-Sep.csv\n",
      "2018-Oct-Dec.csv\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "# find files of interest by year\n",
    "for x in range(2013,2019):\n",
    "    for file in os.listdir('membership_data'):\n",
    "        if file.startswith(str(x)):\n",
    "            print(file)\n",
    "            \n",
    "    print('----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created bulk CSV for 2013...\n",
      "Created bulk CSV for 2014...\n",
      "Created bulk CSV for 2015...\n",
      "Created bulk CSV for 2016...\n",
      "Created bulk CSV for 2017...\n",
      "Created bulk CSV for 2018...\n"
     ]
    }
   ],
   "source": [
    "# combine quarterly data for annual data\n",
    "for x in range(2013,2019):\n",
    "    quarters = []\n",
    "    for file in os.listdir('membership_data/'):\n",
    "        if file.startswith(str(x)):\n",
    "            df = pd.read_csv(f'membership_data/{file}')\n",
    "            quarters.append(df)\n",
    "\n",
    "    # combine and sort by date, ensure type\n",
    "    year_df = pd.concat(quarters,ignore_index=True,sort=False)\n",
    "    year_df['Date'] = pd.to_datetime(year_df.Date)\n",
    "    year_df = year_df.sort_values(by='Date')\n",
    "\n",
    "    year_df.to_csv(f'membership_data/output/bulk_{x}.csv',sep=',',index=False)\n",
    "            \n",
    "    print(f'Created bulk CSV for {x}...')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
